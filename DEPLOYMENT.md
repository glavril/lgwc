# Dockeréƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨ä¸åŒç¯å¢ƒä¸­éƒ¨ç½²ç°ä»£åŒ–CMSç³»ç»Ÿï¼ŒåŒ…æ‹¬ç³»ç»Ÿè¦æ±‚ã€å®‰è£…æ­¥éª¤ã€é…ç½®è¯´æ˜ã€å¯åŠ¨æœåŠ¡ã€éªŒè¯æµ‹è¯•å’Œæ•…éšœæ’æŸ¥ç­‰å†…å®¹ã€‚

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å®‰è£…æ­¥éª¤](#å®‰è£…æ­¥éª¤)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [å¯åŠ¨æœåŠ¡](#å¯åŠ¨æœåŠ¡)
- [éªŒè¯æµ‹è¯•](#éªŒè¯æµ‹è¯•)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
- [æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜)
- [å®‰å…¨åŠ å›º](#å®‰å…¨åŠ å›º)
- [ç›‘æ§ç»´æŠ¤](#ç›‘æ§ç»´æŠ¤)

## ğŸ–¥ï¸ ç³»ç»Ÿè¦æ±‚

### æœ€ä½è¦æ±‚

| ç»„ä»¶ | æœ€ä½é…ç½® | æ¨èé…ç½® | è¯´æ˜ |
|------|----------|----------|------|
| CPU | 2æ ¸å¿ƒ | 4æ ¸å¿ƒ | å¤„ç†APIè¯·æ±‚å’Œæ•°æ®åº“æŸ¥è¯¢ |
| å†…å­˜ | 2GB | 4GB+ | Dockerå®¹å™¨å’Œæ•°æ®åº“è¿è¡Œ |
| å­˜å‚¨ | 10GB | 50GB+ | ç³»ç»Ÿæ–‡ä»¶ã€æ•°æ®åº“ã€æ—¥å¿— |
| ç½‘ç»œ | 1Mbps | 10Mbps+ | åº”ç”¨è®¿é—®å’Œå†…å®¹ä¼ è¾“ |

### è½¯ä»¶ä¾èµ–

| è½¯ä»¶ | ç‰ˆæœ¬è¦æ±‚ | å®‰è£…è¯´æ˜ |
|------|----------|----------|
| Docker Engine | 19.03+ | [Dockerå®˜æ–¹æ–‡æ¡£](https://docs.docker.com/engine/install/) |
| Docker Compose | 1.25+ | [Composeå®˜æ–¹æ–‡æ¡£](https://docs.docker.com/compose/install/) |
| æ“ä½œç³»ç»Ÿ | Linux/macOS/Windows | æ¨èUbuntu 20.04+ã€macOS 10.15+ã€Windows 10+ |
| å†…æ ¸ | Linux 4.15+ | ä»…Linuxç³»ç»Ÿ |

### ç«¯å£è¦æ±‚

| ç«¯å£ | æœåŠ¡ | ç”¨é€” | å¤–éƒ¨è®¿é—® |
|------|------|------|----------|
| 80 | Nginx | HTTPå…¥å£ | âœ… |
| 443 | Nginx | HTTPSå…¥å£ | âœ… |
| 8000 | FastAPI | APIæœåŠ¡ | âš ï¸ (ä»…å¼€å‘) |
| 3000 | Admin Frontend | ç®¡ç†åå° | âš ï¸ (ä»…å¼€å‘) |
| 3001 | Blog Frontend | åšå®¢å‰ç«¯ | âš ï¸ (ä»…å¼€å‘) |
| 5432 | PostgreSQL | æ•°æ®åº“ | âŒ |
| 6379 | Redis | ç¼“å­˜ | âŒ |

## ğŸ”§ å®‰è£…æ­¥éª¤

### 1. Dockerå®‰è£…

#### Ubuntu/Debianç³»ç»Ÿ

```bash
# æ›´æ–°åŒ…ç´¢å¼•
sudo apt update

# å®‰è£…ä¾èµ–
sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release

# æ·»åŠ Dockerå®˜æ–¹GPGå¯†é’¥
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# è®¾ç½®ç¨³å®šç‰ˆä»“åº“
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# å®‰è£…Docker Engine
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io docker compose-plugin

# å¯åŠ¨DockeræœåŠ¡
sudo systemctl start docker
sudo systemctl enable docker

# å°†å½“å‰ç”¨æˆ·æ·»åŠ åˆ°dockerç»„
sudo usermod -aG docker $USER

# é‡æ–°ç™»å½•æˆ–æ‰§è¡Œ
newgrp docker
```

#### CentOS/RHELç³»ç»Ÿ

```bash
# å®‰è£…Docker
sudo yum install -y yum-utils
sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
sudo yum install docker-ce docker-ce-cli containerd.io docker compose-plugin

# å¯åŠ¨æœåŠ¡
sudo systemctl start docker
sudo systemctl enable docker

# æ·»åŠ ç”¨æˆ·åˆ°dockerç»„
sudo usermod -aG docker $USER
```

#### macOSç³»ç»Ÿ

```bash
# ä½¿ç”¨Homebrewå®‰è£…
brew install --cask docker

# æˆ–è€…ä¸‹è½½Docker Desktop
# https://www.docker.com/products/docker-desktop
```

#### Windowsç³»ç»Ÿ

1. ä¸‹è½½å¹¶å®‰è£… [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop)
2. å¯ç”¨WSL 2åŠŸèƒ½
3. é‡å¯ç³»ç»Ÿ

### 2. Docker ComposeéªŒè¯

```bash
# éªŒè¯Dockerå®‰è£…
docker --version
docker compose --version

# æµ‹è¯•Dockerè¿è¡Œ
docker run hello-world
```

## âš™ï¸ ç¯å¢ƒé…ç½®

### 1. é¡¹ç›®æ–‡ä»¶å‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®ï¼ˆæˆ–ä¸‹è½½é¡¹ç›®æ–‡ä»¶ï¼‰
git clone <repository-url>
cd modern-cms

# æ£€æŸ¥é¡¹ç›®æ–‡ä»¶ç»“æ„
ls -la
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

#### åˆ›å»ºç”Ÿäº§ç¯å¢ƒé…ç½®

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env.prod

# ç¼–è¾‘ç”Ÿäº§ç¯å¢ƒé…ç½®
vim .env.prod
```

#### ç¯å¢ƒå˜é‡è¯¦è§£

```bash
# ===========================================
# æ•°æ®åº“é…ç½®
# ===========================================
DATABASE_URL=postgresql://username:password@postgres:5432/cms_db
DATABASE_ASYNC_URL=postgresql+asyncpg://username:password@postgres:5432/cms_db

# ===========================================
# Redisé…ç½®
# ===========================================
REDIS_URL=redis://redis:6379/0

# ===========================================
# åº”ç”¨é…ç½®
# ===========================================
SECRET_KEY=your-super-secret-key-change-in-production-min-32-chars
DEBUG=false
APP_ENV=production
APP_NAME="Modern CMS"
APP_VERSION=1.0.0

# ===========================================
# å®‰å…¨é…ç½®
# ===========================================
ALLOWED_ORIGINS=https://yourdomain.com,https://admin.yourdomain.com
CORS_ALLOW_CREDENTIALS=true

# ===========================================
# æ–‡ä»¶ä¸Šä¼ é…ç½®
# ===========================================
MAX_FILE_SIZE=10485760  # 10MB
UPLOAD_DIR=/app/uploads

# ===========================================
# é‚®ä»¶é…ç½® (å¯é€‰)
# ===========================================
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password
SMTP_USE_TLS=true

# ===========================================
# æ—¥å¿—é…ç½®
# ===========================================
LOG_LEVEL=INFO
LOG_FORMAT=json

# ===========================================
# ç¼“å­˜é…ç½®
# ===========================================
CACHE_TTL=3600  # 1å°æ—¶
SESSION_TTL=86400  # 24å°æ—¶
```

#### Docker Composeé…ç½®

```yaml
# docker compose.prod.yml
version: '3.8'

services:
  # PostgreSQLæ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: cms_postgres
    environment:
      POSTGRES_USER: ${DB_USERNAME:-postgres}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME:-cms_db}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups  # å¤‡ä»½ç›®å½•
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USERNAME:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - cms_network

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: cms_redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped
    networks:
      - cms_network

  # FastAPIåç«¯
  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: cms_api
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - DATABASE_ASYNC_URL=${DATABASE_ASYNC_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
      - DEBUG=${DEBUG}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS}
      - LOG_LEVEL=${LOG_LEVEL}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - cms_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginxåå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: cms_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro  # SSLè¯ä¹¦ç›®å½•
      - nginx_logs:/var/log/nginx
    depends_on:
      - api
      - admin
      - blog
    restart: unless-stopped
    networks:
      - cms_network

volumes:
  postgres_data:
  redis_data:
  nginx_logs:

networks:
  cms_network:
    driver: bridge
```

### 3. Nginxç”Ÿäº§é…ç½®

åˆ›å»ºç”Ÿäº§ç¯å¢ƒNginxé…ç½®æ–‡ä»¶ `nginx/nginx.prod.conf`:

```nginx
# ä¸»é…ç½®
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    # åŸºç¡€è®¾ç½®
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';
    
    access_log /var/log/nginx/access.log main;
    
    # æ€§èƒ½ä¼˜åŒ–
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 10M;
    
    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    
    # å®‰å…¨å¤´
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header Referrer-Policy "no-referrer-when-downgrade" always;
    add_header Content-Security-Policy "default-src 'self' http: https: data: blob: 'unsafe-inline'" always;
    
    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream api_backend {
        server api:8000;
        keepalive 32;
    }
    
    upstream admin_backend {
        server admin:80;
        keepalive 32;
    }
    
    upstream blog_backend {
        server blog:80;
        keepalive 32;
    }
    
    # HTTPé‡å®šå‘åˆ°HTTPS
    server {
        listen 80;
        server_name _;
        return 301 https://$server_name$request_uri;
    }
    
    # HTTPSä¸»æœåŠ¡å™¨
    server {
        listen 443 ssl http2;
        server_name yourdomain.com www.yourdomain.com;
        
        # SSLè¯ä¹¦é…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;
        
        # APIä»£ç†
        location /api/ {
            proxy_pass http://api_backend/api/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }
        
        # é™æ€æ–‡ä»¶ä»£ç† (APIæœåŠ¡)
        location /uploads/ {
            proxy_pass http://api_backend/uploads/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_cache_valid 200 302 1h;
            proxy_cache_valid 404 1m;
            expires 1h;
        }
        
        # ç®¡ç†åå°
        location /admin/ {
            proxy_pass http://admin_backend/admin/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # åšå®¢å‰ç«¯
        location / {
            proxy_pass http://blog_backend/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

## ğŸš€ å¯åŠ¨æœåŠ¡

### å¼€å‘ç¯å¢ƒå¯åŠ¨

```bash
# 1. å¯åŠ¨åŸºç¡€æœåŠ¡ (æ•°æ®åº“ã€ç¼“å­˜)
docker compose up -d postgres redis

# 2. ç­‰å¾…æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ
docker compose logs postgres

# 3. å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker compose up -d

# 4. æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker compose ps
```

### ç”Ÿäº§ç¯å¢ƒå¯åŠ¨

```bash
# 1. æ„å»ºç”Ÿäº§é•œåƒ
docker compose -f docker compose.yml -f docker compose.prod.yml build --no-cache

# 2. åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p nginx/logs nginx/ssl backups

# 3. è®¾ç½®SSLè¯ä¹¦ (å¦‚æœæ²¡æœ‰)
# å°†æ‚¨çš„SSLè¯ä¹¦æ”¾åˆ° nginx/ssl/ ç›®å½•
# cert.pem - è¯ä¹¦æ–‡ä»¶
# key.pem - ç§é’¥æ–‡ä»¶

# 4. å¯åŠ¨ç”Ÿäº§æœåŠ¡
docker compose -f docker compose.yml -f docker compose.prod.yml up -d

# 5. æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker compose -f docker compose.yml -f docker compose.prod.yml ps
```

### æœåŠ¡ä¾èµ–é¡ºåº

å¯åŠ¨é¡ºåºå¾ˆé‡è¦ï¼Œç¡®ä¿ä¾èµ–æœåŠ¡å…ˆå¯åŠ¨ï¼š

```bash
# 1. é¦–å…ˆå¯åŠ¨åŸºç¡€è®¾æ–½æœåŠ¡
docker compose up -d postgres redis

# 2. ç­‰å¾…æ•°æ®åº“å°±ç»ª (çº¦30ç§’)
sleep 30

# 3. æ£€æŸ¥æ•°æ®åº“å¥åº·çŠ¶æ€
docker compose exec postgres pg_isready

# 4. å¯åŠ¨åº”ç”¨æœåŠ¡
docker compose up -d api

# 5. å¯åŠ¨å‰ç«¯æœåŠ¡
docker compose up -d admin blog

# 6. æœ€åå¯åŠ¨Nginx
docker compose up -d nginx
```

## âœ… éªŒè¯æµ‹è¯•

### 1. åŸºç¡€è¿æ¥æµ‹è¯•

```bash
# æ£€æŸ¥æ‰€æœ‰å®¹å™¨çŠ¶æ€
docker compose ps

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker compose logs --tail=50

# æ£€æŸ¥å®¹å™¨èµ„æºä½¿ç”¨
docker stats
```

### 2. æœåŠ¡ç«¯ç‚¹æµ‹è¯•

#### APIå¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥APIæœåŠ¡å¥åº·çŠ¶æ€
curl -f http://localhost:8000/health

# æ£€æŸ¥APIæ–‡æ¡£
curl -f http://localhost:8000/docs

# æ£€æŸ¥APIæ ¹è·¯å¾„
curl -f http://localhost:8000/
```

#### å‰ç«¯æœåŠ¡æµ‹è¯•

```bash
# æ£€æŸ¥ç®¡ç†åå°
curl -f -I http://localhost:3000

# æ£€æŸ¥åšå®¢å‰ç«¯
curl -f -I http://localhost:3001

# æ£€æŸ¥Nginxä»£ç†
curl -f -I http://localhost/admin
curl -f -I http://localhost/
```

### 3. æ•°æ®åº“è¿æ¥æµ‹è¯•

```bash
# æ£€æŸ¥PostgreSQLè¿æ¥
docker compose exec postgres psql -U postgres -d cms_db -c "SELECT version();"

# æ£€æŸ¥Redisè¿æ¥
docker compose exec redis redis-cli ping

# æ£€æŸ¥æ•°æ®åº“è¿æ¥æ•°
docker compose exec postgres psql -U postgres -d cms_db -c "SELECT count(*) FROM pg_stat_activity;"
```

### 4. åŠŸèƒ½æµ‹è¯•

#### ç”¨æˆ·æ³¨å†Œæµ‹è¯•

```bash
# ä½¿ç”¨curlæµ‹è¯•ç”¨æˆ·æ³¨å†Œ
curl -X POST "http://localhost:8000/api/v1/auth/register" \
  -H "Content-Type: application/json" \
  -d '{
    "username": "testuser",
    "email": "test@example.com",
    "password": "testpassword123",
    "display_name": "Test User"
  }'
```

#### å†…å®¹åˆ›å»ºæµ‹è¯•

```bash
# é¦–å…ˆç™»å½•è·å–token
TOKEN=$(curl -s -X POST "http://localhost:8000/api/v1/auth/login" \
  -H "Content-Type: application/json" \
  -d '{"username": "testuser", "password": "testpassword123"}' | \
  python -c "import sys, json; print(json.load(sys.stdin)['access_token'])")

# åˆ›å»ºå†…å®¹
curl -X POST "http://localhost:8000/api/v1/content" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "æµ‹è¯•æ–‡ç« ",
    "content": "è¿™æ˜¯ä¸€ç¯‡æµ‹è¯•æ–‡ç« çš„å†…å®¹",
    "content_type": "post",
    "status": "published"
  }'
```

### 5. æ€§èƒ½æµ‹è¯•

#### è´Ÿè½½æµ‹è¯•å·¥å…·å®‰è£…

```bash
# å®‰è£…Apache Bench (Ubuntu/Debian)
sudo apt install apache2-utils

# æˆ–å®‰è£…hey (Goç‰ˆæœ¬)
curl -LO https://github.com/rakyll/hey/releases/download/v0.0.1/hey_linux_amd64
chmod +x hey_linux_amd64
sudo mv hey_linux_amd64 /usr/local/bin/hey
```

#### åŸºç¡€æ€§èƒ½æµ‹è¯•

```bash
# APIå“åº”æ—¶é—´æµ‹è¯•
hey -n 100 -c 10 http://localhost:8000/health

# ç®¡ç†é¡µé¢æ€§èƒ½æµ‹è¯•
hey -n 50 -c 5 http://localhost/admin

# åšå®¢é¦–é¡µæ€§èƒ½æµ‹è¯•
hey -n 100 -c 10 http://localhost/
```

### 6. å®‰å…¨æµ‹è¯•

```bash
# æ£€æŸ¥HTTPå¤´å®‰å…¨æ€§
curl -I http://localhost/ | grep -E "(X-Frame-Options|X-XSS-Protection|X-Content-Type-Options)"

# æ£€æŸ¥SSLé…ç½® (å¦‚æœä½¿ç”¨HTTPS)
ssl-checker yourdomain.com 443

# æ£€æŸ¥æ•æ„Ÿæ–‡ä»¶è®¿é—®
curl -f http://localhost/.env || echo "ç¯å¢ƒæ–‡ä»¶ä¸å¯è®¿é—® (æ­£ç¡®)"
curl -f http://localhost/admin/.env || echo "ç®¡ç†åå°ç¯å¢ƒæ–‡ä»¶ä¸å¯è®¿é—® (æ­£ç¡®)"
```

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜è¯Šæ–­

#### 1. å®¹å™¨æ— æ³•å¯åŠ¨

**ç—‡çŠ¶**: å®¹å™¨çŠ¶æ€ä¸ºExitedæˆ–Restarting

```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker compose logs [service_name]

# æ£€æŸ¥é…ç½®æ–‡ä»¶è¯­æ³•
docker compose config

# æ£€æŸ¥ç«¯å£å ç”¨
sudo netstat -tulpn | grep :80
sudo netstat -tulpn | grep :443
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ¸…ç†å¹¶é‡æ–°åˆ›å»ºå®¹å™¨
docker compose down -v
docker compose up -d --force-recreate

# é‡æ–°æ„å»ºé•œåƒ
docker compose build --no-cache
docker compose up -d
```

#### 2. æ•°æ®åº“è¿æ¥å¤±è´¥

**ç—‡çŠ¶**: APIæœåŠ¡æ— æ³•è¿æ¥æ•°æ®åº“

```bash
# æ£€æŸ¥æ•°æ®åº“å®¹å™¨çŠ¶æ€
docker compose ps postgres

# æ£€æŸ¥æ•°æ®åº“æ—¥å¿—
docker compose logs postgres

# æµ‹è¯•æ•°æ®åº“è¿æ¥
docker compose exec postgres pg_isready -U postgres

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker compose exec api ping postgres
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# é‡å¯æ•°æ®åº“æœåŠ¡
docker compose restart postgres

# æ£€æŸ¥ç¯å¢ƒå˜é‡
docker compose exec api env | grep DATABASE

# æ‰‹åŠ¨è¿æ¥æµ‹è¯•
docker compose exec postgres psql -U postgres -d cms_db
```

#### 3. å‰ç«¯æ— æ³•è®¿é—®API

**ç—‡çŠ¶**: æµè§ˆå™¨æ§åˆ¶å°æ˜¾ç¤ºCORSé”™è¯¯æˆ–ç½‘ç»œé”™è¯¯

```bash
# æ£€æŸ¥CORSé…ç½®
curl -H "Origin: http://localhost:3000" \
     -H "Access-Control-Request-Method: POST" \
     -H "Access-Control-Request-Headers: X-Requested-With" \
     -X OPTIONS \
     http://localhost:8000/api/v1/content

# æ£€æŸ¥APIæœåŠ¡çŠ¶æ€
docker compose logs api
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®
docker compose exec api env | grep ALLOWED_ORIGINS

# é‡å¯APIæœåŠ¡
docker compose restart api

# æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
sudo ufw status
sudo iptables -L
```

#### 4. å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: å®¹å™¨è¢«æ€ï¼Œç³»ç»Ÿå“åº”æ…¢

```bash
# æ£€æŸ¥ç³»ç»Ÿèµ„æº
free -h
df -h
docker stats

# æ£€æŸ¥å®¹å™¨å†…å­˜ä½¿ç”¨
docker compose exec api free -h
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# å¢åŠ ç³»ç»Ÿswap
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# ä¼˜åŒ–Dockeré…ç½®
# ç¼–è¾‘ /etc/docker/daemon.json
{
  "default-runtime": "runc",
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  },
  "storage-driver": "overlay2",
  "default-ulimits": {
    "nofile": {
      "Name": "nofile",
      "Hard": 64000,
      "Soft": 64000
    }
  }
}

# é‡å¯DockeræœåŠ¡
sudo systemctl restart docker
```

#### 5. ç£ç›˜ç©ºé—´ä¸è¶³

**ç—‡çŠ¶**: æ— æ³•å†™å…¥æ–‡ä»¶ï¼Œå®¹å™¨å´©æºƒ

```bash
# æ£€æŸ¥ç£ç›˜ä½¿ç”¨æƒ…å†µ
df -h
du -sh /var/lib/docker

# æ¸…ç†Dockerèµ„æº
docker system prune -a
docker volume prune

# æ¸…ç†æ—¥å¿—æ–‡ä»¶
sudo find /var/lib/docker/containers/*/ -name "*.log" -exec truncate -s 0 {} \;
```

### æ—¥å¿—åˆ†æ

#### å®æ—¶æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker compose logs -f api
docker compose logs -f postgres

# æŸ¥çœ‹æœ€è¿‘Nè¡Œæ—¥å¿—
docker compose logs --tail=100 api
```

#### æ—¥å¿—çº§åˆ«åˆ†æ

```bash
# è¿‡æ»¤é”™è¯¯æ—¥å¿—
docker compose logs api | grep -i error
docker compose logs api | grep -i exception

# è¿‡æ»¤è­¦å‘Šæ—¥å¿—
docker compose logs nginx | grep -i warn
```

### ç½‘ç»œè¯Šæ–­

```bash
# æ£€æŸ¥å®¹å™¨ç½‘ç»œ
docker network ls
docker network inspect workspace_cms_network

# æ£€æŸ¥DNSè§£æ
docker compose exec api nslookup postgres
docker compose exec api getent hosts redis

# æµ‹è¯•ç½‘ç»œè¿é€šæ€§
docker compose exec api curl -f http://postgres:5432
docker compose exec api curl -f http://redis:6379
```

## âš¡ æ€§èƒ½è°ƒä¼˜

### 1. æ•°æ®åº“ä¼˜åŒ–

#### PostgreSQLé…ç½®ä¼˜åŒ–

åˆ›å»º `postgresql.conf`:

```sql
-- å†…å­˜è®¾ç½®
shared_buffers = 256MB              -- 1/4å†…å­˜
effective_cache_size = 1GB          -- 3/4å†…å­˜
work_mem = 4MB                      -- å•æŸ¥è¯¢å†…å­˜
maintenance_work_mem = 64MB         -- ç»´æŠ¤æ“ä½œå†…å­˜

-- è¿æ¥è®¾ç½®
max_connections = 200
superuser_reserved_connections = 3

-- WALè®¾ç½®
wal_buffers = 16MB
checkpoint_completion_target = 0.7
wal_keep_size = 1GB

-- æŸ¥è¯¢è®¡åˆ’
random_page_cost = 1.1              -- SSDä¼˜åŒ–
effective_io_concurrency = 200

-- æ—¥å¿—è®¾ç½®
log_min_duration_statement = 1000   -- è®°å½•æ…¢æŸ¥è¯¢
log_checkpoints = on
log_connections = on
log_disconnections = on
log_lock_waits = on

-- è‡ªåŠ¨ç»Ÿè®¡ä¿¡æ¯
track_activities = on
track_counts = on
track_io_timing = on
```

#### æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–

```sql
-- åˆ›å»ºæ€§èƒ½ç›‘æ§è¡¨
CREATE TABLE IF NOT EXISTS query_stats AS
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    rows
FROM pg_stat_statements
WHERE mean_time > 100  -- è®°å½•å¹³å‡æ‰§è¡Œæ—¶é—´è¶…è¿‡100msçš„æŸ¥è¯¢
ORDER BY mean_time DESC;

-- åˆ›å»ºå¸¸ç”¨æŸ¥è¯¢çš„å¤åˆç´¢å¼•
CREATE INDEX CONCURRENTLY idx_content_type_status_published 
ON content(content_type, status, published_at DESC) 
WHERE status = 'published';

-- åˆ›å»ºJSONBå­—æ®µç´¢å¼•
CREATE INDEX CONCURRENTLY idx_content_metadata_gin 
ON content USING GIN(metadata);

-- åˆ›å»ºå…¨æ–‡æœç´¢ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_content_search_gin 
ON content USING GIN(to_tsvector('english', title || ' ' || COALESCE(excerpt, '')));
```

### 2. Redisä¼˜åŒ–

#### Redisé…ç½®ä¼˜åŒ–

```bash
# å¤‡ä»½åŸæœ‰é…ç½®
cp /etc/redis/redis.conf /etc/redis/redis.conf.backup

# ä¼˜åŒ–é…ç½®
redis-cli config set maxmemory 512mb
redis-cli config set maxmemory-policy allkeys-lru
redis-cli config set save "900 1 300 10 60 10000"
```

#### åº”ç”¨å±‚ç¼“å­˜ç­–ç•¥

```python
# Redisç¼“å­˜é…ç½®ç¤ºä¾‹
CACHE_CONFIG = {
    "default": {
        "BACKEND": "django_redis.cache.RedisCache",
        "LOCATION": "redis://redis:6379/0",
        "OPTIONS": {
            "CLIENT_CLASS": "django_redis.client.DefaultClient",
            "COMPRESSOR": "django_redis.compressors.zlib.ZlibCompressor",
            "SERIALIZER": "django_redis.serializers.json.JSONSerializer",
        }
    }
}

# ç¼“å­˜ç­–ç•¥
CACHE_TTL = {
    "content": 3600,      # å†…å®¹ç¼“å­˜1å°æ—¶
    "user_profile": 1800, # ç”¨æˆ·èµ„æ–™ç¼“å­˜30åˆ†é’Ÿ
    "menu": 7200,         # èœå•ç¼“å­˜2å°æ—¶
    "settings": 86400,    # è®¾ç½®ç¼“å­˜24å°æ—¶
}
```

### 3. Nginxä¼˜åŒ–

#### é™æ€æ–‡ä»¶ç¼“å­˜

```nginx
# é™æ€æ–‡ä»¶ç¼“å­˜é…ç½®
location ~* \.(jpg|jpeg|png|gif|ico|css|js|woff|woff2|ttf|svg|eot)$ {
    expires 1y;
    add_header Cache-Control "public, immutable";
    add_header Vary Accept-Encoding;
    gzip_static on;
}

# åª’ä½“æ–‡ä»¶ç¼“å­˜
location /uploads/ {
    expires 1M;
    add_header Cache-Control "public";
    add_header Vary Accept-Encoding;
    
    # å¯ç”¨sendfile
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    
    # å¯ç”¨ç¼“å­˜
    proxy_cache_valid 200 302 1h;
    proxy_cache_valid 404 1m;
    expires 1h;
}
```

#### è¿æ¥ä¼˜åŒ–

```nginx
# è¿æ¥ä¼˜åŒ–
worker_connections 1024;
use epoll;
multi_accept on;

# ç¼“å†²åŒºä¼˜åŒ–
client_body_buffer_size 128k;
client_header_buffer_size 1k;
large_client_header_buffers 4 4k;
output_buffers 1 32k;
postpone_output 1460;

# è¶…æ—¶è®¾ç½®
client_body_timeout 12;
client_header_timeout 12;
keepalive_timeout 15;
send_timeout 10;
```

### 4. åº”ç”¨ä¼˜åŒ–

#### FastAPIä¼˜åŒ–

```python
# main.py æ€§èƒ½ä¼˜åŒ–
from fastapi import FastAPI
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(
    title="Modern CMS",
    docs_url="/docs" if settings.DEBUG else None,  # ç”Ÿäº§ç¯å¢ƒå…³é—­æ–‡æ¡£
    redoc_url="/redoc" if settings.DEBUG else None,
)

# æ·»åŠ Gzipå‹ç¼©
app.add_middleware(GZipMiddleware, minimum_size=1000)

# CORSä¼˜åŒ–
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
    max_age=86400,  # 24å°æ—¶ç¼“å­˜é¢„æ£€è¯·æ±‚
)
```

#### æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

```python
# database.py
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

# æ•°æ®åº“è¿æ¥æ± é…ç½®
engine = create_engine(
    settings.DATABASE_URL,
    poolclass=QueuePool,
    pool_size=20,           # è¿æ¥æ± å¤§å°
    max_overflow=30,        # æº¢å‡ºè¿æ¥æ•°
    pool_pre_ping=True,     # é¢„æ£€è¿æ¥
    pool_recycle=3600,      # è¿æ¥å›æ”¶æ—¶é—´
    echo=settings.DEBUG,    # SQLæ—¥å¿— (ä»…å¼€å‘)
)
```

## ğŸ”’ å®‰å…¨åŠ å›º

### 1. å®¹å™¨å®‰å…¨

#### érootç”¨æˆ·è¿è¡Œ

```dockerfile
# Dockerfile.backend
FROM python:3.11-slim

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r appuser && useradd -r -g appuser appuser

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦ç›®å½•
RUN mkdir -p /app/uploads && chown -R appuser:appuser /app

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER appuser

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨åº”ç”¨
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### åªè¯»æ–‡ä»¶ç³»ç»Ÿ

```yaml
# docker compose.prod.yml
services:
  api:
    build: ./backend
    read_only: true
    tmpfs:
      - /tmp
      - /app/uploads
    volumes:
      - ./uploads:/app/uploads:rw
```

#### å®‰å…¨èƒ½åŠ›é™åˆ¶

```yaml
services:
  api:
    build: ./backend
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - FOWNER
      - SETGID
      - SETUID
    security_opt:
      - no-new-privileges:true
```

### 2. ç½‘ç»œå®‰å…¨

#### ç½‘ç»œéš”ç¦»

```yaml
services:
  postgres:
    networks:
      - database_network
  
  redis:
    networks:
      - cache_network
  
  api:
    networks:
      - app_network
      - database_network
      - cache_network

networks:
  database_network:
    driver: bridge
    internal: true  # å†…éƒ¨ç½‘ç»œ
  
  cache_network:
    driver: bridge
    internal: true
  
  app_network:
    driver: bridge
```

#### ç«¯å£é™åˆ¶

```yaml
services:
  postgres:
    ports: []  # ä¸æš´éœ²ç«¯å£
  
  redis:
    ports: []  # ä¸æš´éœ²ç«¯å£
  
  nginx:
    ports:
      - "80:80"
      - "443:443"
```

### 3. æ•°æ®å®‰å…¨

#### ç¯å¢ƒå˜é‡åŠ å¯†

```bash
# ä½¿ç”¨Docker secrets (æ¨è)
echo "my-secret-password" | docker secret create db_password -

# æˆ–è€…ä½¿ç”¨å¤–éƒ¨å¯†é’¥ç®¡ç†
# AWS Secrets Manager, HashiCorp Vaultç­‰
```

#### æ•°æ®åŠ å¯†

```sql
-- å¯ç”¨è¡¨ç©ºé—´åŠ å¯†
ALTER TABLESPACE encrypted_ts ENCRYPTION ON;

-- æ•æ„Ÿå­—æ®µåŠ å¯†
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- åˆ›å»ºåŠ å¯†å‡½æ•°
CREATE OR REPLACE FUNCTION encrypt_field(plaintext TEXT)
RETURNS TEXT AS $$
BEGIN
  RETURN encode(encrypt(plaintext::bytea, 'encryption_key', 'aes'), 'base64');
END;
$$ LANGUAGE plpgsql;
```

### 4. è®¿é—®æ§åˆ¶

#### é˜²ç«å¢™é…ç½®

```bash
# Ubuntu/Debian
sudo ufw enable
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw allow from 192.168.1.0/24 to any port 22

# CentOS/RHEL
sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https
sudo firewall-cmd --reload
```

#### SSHå®‰å…¨

```bash
# ç¦ç”¨rootç™»å½•
sudo sed -i 's/PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config

# ç¦ç”¨å¯†ç ç™»å½•
sudo sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config

# ä¿®æ”¹SSHç«¯å£
sudo sed -i 's/#Port 22/Port 2222/' /etc/ssh/sshd_config

# é‡å¯SSHæœåŠ¡
sudo systemctl restart ssh
```

## ğŸ“Š ç›‘æ§ç»´æŠ¤

### 1. å¥åº·æ£€æŸ¥

#### åº”ç”¨å±‚å¥åº·æ£€æŸ¥

```python
# health_check.py
from fastapi import FastAPI
from sqlalchemy import text
import redis
import httpx

app = FastAPI()

@app.get("/health/detailed")
async def detailed_health_check():
    health_status = {
        "status": "healthy",
        "timestamp": time.time(),
        "checks": {}
    }
    
    # æ•°æ®åº“å¥åº·æ£€æŸ¥
    try:
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            health_status["checks"]["database"] = {"status": "healthy"}
    except Exception as e:
        health_status["checks"]["database"] = {"status": "unhealthy", "error": str(e)}
        health_status["status"] = "unhealthy"
    
    # Rediså¥åº·æ£€æŸ¥
    try:
        r.ping()
        health_status["checks"]["redis"] = {"status": "healthy"}
    except Exception as e:
        health_status["checks"]["redis"] = {"status": "unhealthy", "error": str(e)}
        health_status["status"] = "unhealthy"
    
    # å¤–éƒ¨APIå¥åº·æ£€æŸ¥
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("https://httpbin.org/status/200", timeout=5)
            health_status["checks"]["external_api"] = {"status": "healthy"}
    except Exception as e:
        health_status["checks"]["external_api"] = {"status": "unhealthy", "error": str(e)}
    
    return health_status
```

#### Dockerå¥åº·æ£€æŸ¥

```yaml
services:
  api:
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
  
  postgres:
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
  
  redis:
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
```

### 2. æ—¥å¿—æ”¶é›†

#### ç»“æ„åŒ–æ—¥å¿—

```python
# logging_config.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno,
        }
        
        # æ·»åŠ é¢å¤–å­—æ®µ
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
        
        return json.dumps(log_entry)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    handlers=[logging.StreamHandler()],
    format='%(message)s'
)

# åº”ç”¨JSONæ ¼å¼åŒ–å™¨
logger = logging.getLogger()
handler = logging.StreamHandler()
handler.setFormatter(JSONFormatter())
logger.handlers.clear()
logger.addHandler(handler)
```

#### æ—¥å¿—è½®è½¬

```yaml
# docker compose.yml
services:
  api:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
  
  postgres:
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
```

### 3. æ€§èƒ½ç›‘æ§

#### èµ„æºç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# monitor.sh - ç³»ç»Ÿç›‘æ§è„šæœ¬

# æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡
DISK_USAGE=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 80 ]; then
    echo "è­¦å‘Š: ç£ç›˜ä½¿ç”¨ç‡è¾¾åˆ° ${DISK_USAGE}%"
    # å‘é€å‘Šè­¦
fi

# æ£€æŸ¥å†…å­˜ä½¿ç”¨ç‡
MEMORY_USAGE=$(free | awk 'NR==2{printf "%.2f", $3*100/$2}')
if (( $(echo "$MEMORY_USAGE > 80" | bc -l) )); then
    echo "è­¦å‘Š: å†…å­˜ä½¿ç”¨ç‡è¾¾åˆ° ${MEMORY_USAGE}%"
fi

# æ£€æŸ¥å®¹å™¨çŠ¶æ€
UNHEALTHY_CONTAINERS=$(docker compose ps --filter health=unhealthy -q | wc -l)
if [ $UNHEALTHY_CONTAINERS -gt 0 ]; then
    echo "è­¦å‘Š: å‘ç° $UNHEALTHY_CONTAINERS ä¸ªä¸å¥åº·çš„å®¹å™¨"
fi

# æ£€æŸ¥APIå“åº”æ—¶é—´
API_RESPONSE_TIME=$(curl -w "%{time_total}" -s -o /dev/null http://localhost:8000/health)
if (( $(echo "$API_RESPONSE_TIME > 1.0" | bc -l) )); then
    echo "è­¦å‘Š: APIå“åº”æ—¶é—´è¶…è¿‡1ç§’: ${API_RESPONSE_TIME}s"
fi
```

#### Grafanaç›‘æ§é¢æ¿

```yaml
# docker compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  grafana:
    image: grafana/grafana
    ports:
      - "3002:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana

  node_exporter:
    image: prom/node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro

volumes:
  prometheus_data:
  grafana_data:
```

### 4. å¤‡ä»½æ¢å¤

#### è‡ªåŠ¨å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# backup.sh - æ•°æ®åº“å¤‡ä»½è„šæœ¬

BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="cms_backup_${DATE}.sql"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# æ•°æ®åº“å¤‡ä»½
docker compose exec -T postgres pg_dump -U postgres cms_db > $BACKUP_DIR/$BACKUP_FILE

# å‹ç¼©å¤‡ä»½æ–‡ä»¶
gzip $BACKUP_DIR/$BACKUP_FILE

# åˆ é™¤7å¤©å‰çš„å¤‡ä»½
find $BACKUP_DIR -name "cms_backup_*.sql.gz" -mtime +7 -delete

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨ (å¯é€‰)
# aws s3 cp $BACKUP_DIR/cms_backup_${DATE}.sql.gz s3://your-backup-bucket/

echo "å¤‡ä»½å®Œæˆ: $BACKUP_FILE.gz"
```

#### æ¢å¤è„šæœ¬

```bash
#!/bin/bash
# restore.sh - æ•°æ®åº“æ¢å¤è„šæœ¬

BACKUP_FILE=$1
if [ -z "$BACKUP_FILE" ]; then
    echo "ç”¨æ³•: $0 <backup_file>"
    exit 1
fi

# ç¡®è®¤æ“ä½œ
read -p "è¿™å°†è¦†ç›–å½“å‰æ•°æ®åº“ï¼Œç¡®å®šç»§ç»­? (y/N): " confirm
if [ "$confirm" != "y" ]; then
    echo "æ“ä½œå·²å–æ¶ˆ"
    exit 1
fi

# åœæ­¢åº”ç”¨æœåŠ¡
docker compose stop api

# è§£å‹å¤‡ä»½æ–‡ä»¶
if [[ $BACKUP_FILE == *.gz ]]; then
    gunzip -c $BACKUP_FILE > /tmp/restore.sql
else
    cp $BACKUP_FILE /tmp/restore.sql
fi

# æ¢å¤æ•°æ®åº“
docker compose exec -T postgres psql -U postgres cms_db < /tmp/restore.sql

# é‡å¯åº”ç”¨æœåŠ¡
docker compose start api

echo "æ¢å¤å®Œæˆ"
```

### 5. ç»´æŠ¤ä»»åŠ¡

#### å®šæœŸç»´æŠ¤è„šæœ¬

```bash
#!/bin/bash
# maintenance.sh - å®šæœŸç»´æŠ¤ä»»åŠ¡

echo "å¼€å§‹ç»´æŠ¤ä»»åŠ¡..."

# æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯æ›´æ–°
docker compose exec postgres psql -U postgres cms_db -c "ANALYZE;"

# æ¸…ç†Dockerèµ„æº
docker system prune -f

# æ¸…ç†æ—¥å¿—æ–‡ä»¶
docker compose exec nginx sh -c "find /var/log/nginx -name '*.log' -mtime +7 -delete"

# é‡å¯æœåŠ¡ (å¯é€‰)
# docker compose restart

echo "ç»´æŠ¤ä»»åŠ¡å®Œæˆ"
```

#### å®šæ—¶ä»»åŠ¡é…ç½®

```bash
# æ·»åŠ åˆ°crontab
crontab -e

# æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œå¤‡ä»½
0 2 * * * /path/to/backup.sh

# æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹æ‰§è¡Œç»´æŠ¤
0 3 * * 0 /path/to/maintenance.sh

# æ¯5åˆ†é’Ÿç›‘æ§ä¸€æ¬¡ç³»ç»ŸçŠ¶æ€
*/5 * * * * /path/to/monitor.sh
```

---

## ğŸ¯ æ€»ç»“

æœ¬éƒ¨ç½²æŒ‡å—æ¶µç›–äº†ç°ä»£åŒ–CMSç³»ç»Ÿçš„å®Œæ•´éƒ¨ç½²æµç¨‹ï¼Œä»ç³»ç»Ÿè¦æ±‚åˆ°æ•…éšœæ’æŸ¥ï¼Œä»æ€§èƒ½ä¼˜åŒ–åˆ°å®‰å…¨åŠ å›ºã€‚é€šè¿‡éµå¾ªæœ¬æŒ‡å—ï¼Œæ‚¨å¯ä»¥ï¼š

âœ… **å¿«é€Ÿéƒ¨ç½²**: åœ¨30åˆ†é’Ÿå†…å®Œæˆç”Ÿäº§ç¯å¢ƒéƒ¨ç½²  
âœ… **å®‰å…¨è¿è¡Œ**: é€šè¿‡å¤šå±‚å®‰å…¨æªæ–½ä¿æŠ¤ç³»ç»Ÿ  
âœ… **é«˜æ€§èƒ½**: ä¼˜åŒ–é…ç½®è·å¾—æœ€ä½³æ€§èƒ½  
âœ… **å¯ç›‘æ§**: å®Œå–„çš„ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶  
âœ… **æ˜“ç»´æŠ¤**: è‡ªåŠ¨åŒ–çš„å¤‡ä»½å’Œæ¢å¤æµç¨‹  

å¦‚æœåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·å‚è€ƒ[æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)ç« èŠ‚ï¼Œæˆ–æŸ¥çœ‹é¡¹ç›®çš„GitHub Issuesé¡µé¢è·å–å¸®åŠ©ã€‚

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼** ğŸš€